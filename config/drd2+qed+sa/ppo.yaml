DRD2+QED+SA-PPO:
  Agent:
    type: PPO
    n_steps: 128
    epoch: 6
    seq_len: 75
    seq_mini_batch_size: 16
    gamma: 1.0
  Env:
    drd2_coef: 0.3334
    qed_coef: 0.3333
    sa_coef: 0.3333
    vocab_path: data/drd2+qed+sa/vocab.json
  Train:
    num_envs: 64
    seed: 0
    total_time_steps: 230000
    summary_freq: 1000
    agent_save_freq: 5000
    num_inference_envs: 32
    n_inference_episodes: 1000
    lr: 1.0e-4
    device: cuda
    pretrained_path: data/drd2+qed+sa/pretrained.pt
    refset_path: data/drd2+qed+sa/smiles.txt
  Inference:
    num_envs: 64
    n_episodes: 10000
    seed: 0
    device: cuda
    ckpt: best